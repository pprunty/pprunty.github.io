---
#title: "Is There a Moore's Law for the Human Brain?"
title: "AI vs. Human Brain: The Future of Cognitive Enhancement and Evolution"
date: "2024-07-30"
description: "Exploring the interplay between technological advancements in Artificial Intelligence and the evolution of the human brain."
image: "/images/articles/brain.png"
artwork: "Surgeon examining a human brain"
---

As Artificially Intelligent (AI) systems improve at an exponential rate, are we enhancing our cognitive abilities, or
conversely, is our reliance on technology leading to a cognitive decline?

## The AI Revolution and Human Cognition

[This section serves as the hook, presenting the central question and setting up the tension between AI advancement and human cognitive capabilities]

In 1965, Gordon Moore, co-founder of Intel, observed what would become known today as Moore's Law. Moore's Law states
that the number of transistors
that can be packed onto a piece of silicon doubles approximately every two years. Its limit being the size of a single
atom.
_Huh,_ it would probably be a bad idea for them to go any smaller than that right? You wouldn't want things to start
blowing up...

<figure>
  <img src="https://patrickprunty.com/images/articles/moores-law.jpg" alt="Moore's Law">
  <figcaption>Moore's Law from 1970-2020.</figcaption>
</figure>

This principle has propelled the advancement of AI, as more transistors mean more powerful hardware systems to run AI
programs on. Some fear that these AI systems might eventually surpass human capabilities and 'take over'. However,
OpenAI's latest GPT 4 model utilizes only 1.76 trillion
parameters compared to the human brain's estimated 100 trillion synaptic connections. This vast
difference highlights the unique complexity and evolutionary refinement of the human brain, which spans 3 billion years
of natural evolution.

So, is there a Moore's Law equivalent for the evolution of the human brain?

[//]: # (<iframe width="560" height="315" src="https://www.youtube.com/embed/aQ5PeJjZqBY?si=UIpTD8eXlovMaIoX" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>)

## High-Performance Computing: Driving Computational Evolution

At the beating heart of AI development is high-performance computing. Companies like NVIDIA, which specialize in
manufacturing Graphical Processing Units (GPUs), are the modern-day shuffle manufacturer in today's AI gold rush. This
explains why NVIDIA briefly held the title of the world's most valuable company, surpassing even Microsoft and Apple. In
a recent report by The Financial Times, early Tesla and Amazon backer James Anderson projected NVIDIA to reach a $50
trillion market cap in the next decade, highlighting the company's incalculable potential.

GPUs were initially designed for rendering complex graphics in video games and professional applications. However, their
architecture, consisting of thousands of smaller, more efficient cores, lends itself exceptionally well to parallel
computing â€“ a crucial component in AI processing.

Parallel computing, in simpler terms, is the ability to divide a task into smaller sub-tasks and process them
concurrently. Imagine a team of people working together on a project, where each person handles a specific part of the
work simultaneously. However, unlike human workers who may have varying efficiency, GPU cores operate uniformly,
ensuring consistent and rapid processing speeds.

This parallel processing capability is what makes GPUs ideal for AI applications, particularly in training large neural
networks. The ability to perform multiple calculations simultaneously dramatically speeds up the learning process for AI
models such as ChatGPT, enabling them to process vast amounts of data and recognize complex patterns much faster than
traditional
processors.

While GPUs excel at parallel processing, the human brain operates differently. Our brains are not naturally adept at
parallel processing; instead, they excel at integrating diverse types of information and making complex decisions based
on experience, environment and intuition. A simple test demonstrates this limitation: try alternating between reading letters of the
alphabet and counting numbers, like so: "A, 1, B, 2, C, 3, D, 4 ..."

<figure>
  <img src="https://patrickprunty.com/images/articles/table.png" alt="Brain Exercise">
  <figcaption>Alphabet and Numbers Brain Exercise</figcaption>
</figure>

While this task may seem simple when you can read the information on screen, try it without looking at the table. The
difficulty you'll likely experience highlights the brain's struggle with true parallel tasks.

This contrast between GPU capabilities and human cognition raises intriguing questions about the future of AI and human
intelligence. As we continue to enhance our computational power, how will it shape our approach to problem-solving and
information processing? Will we find ways to augment our natural cognitive abilities with AI-powered tools, or will we
increasingly rely on AI systems to handle tasks our brains aren't optimized for? These questions lead us to consider the
potential for cognitive enhancement and the evolving relationship between human and artificial intelligence.

## The Plasticity of the Human Brain

[Rising action begins here, discussing neuroplasticity and the brain's ability to adapt]

While artificial intelligence progresses through hardware improvements and software updates, the human brain evolves
through a process known as neuroplasticity. This remarkable ability allows our brains to reorganize themselves
by forming new neural connections throughout life, adapting to new experiences, learning, and even recovering from brain
injuries.

The driving force behind the brain's evolution is fundamentally different from that of machines. Where AI systems rely
on external programming and data input, the human brain is shaped by a complex interplay of genetics, environment, and
experience. This dynamic process has been honed over millions of years of evolution, resulting in an organ of
unparalleled adaptability and efficiency.

Research by Maguire et al. (2000) on London taxi drivers revealed that the posterior hippocampi of experienced drivers
were significantly larger than those of control subjects. This study suggests that the brain can physically change in
response to environmental demands and acquired skills within a single lifetime.

These studies underscore a crucial difference between human cognition and artificial intelligence. While AI systems can
be rapidly updated or expanded by adding more processing power or data, the human brain's changes are more gradual but
potentially more profound. Our brains don't just add information; they restructure themselves in response to new
learning and experiences.

This plasticity gives humans a unique advantage in adapting to novel situations and integrating diverse types of
information - capabilities that current AI systems struggle to match. However, it also raises intriguing questions about
the future of human-AI interaction. Could we harness our understanding of neuroplasticity to create more adaptive AI
systems? Or could we use AI to enhance our own neuroplasticity, potentially accelerating learning and cognitive
development?

As we continue to push the boundaries of both human and artificial intelligence, the interplay between neuroplasticity
and technological advancement may hold the key to unlocking new frontiers in cognitive enhancement and evolution.

## Cognitive Enhancement: A New Frontier

[Rising action continues, exploring current and potential future methods of cognitive enhancement]

Elon Musk's Neuralink, for instance, aims to create a direct interface between the brain and computers, potentially
allowing for unprecedented cognitive capabilities.

evolution time for human brain to reach where it is today, first fax machine, first smartphone time, first ... use
graphic sketch

Elon Musk's neuralink & animal trials

Clip of neuralink patient on joe rogan

<iframe width="560" height="315" src="https://www.youtube.com/embed/887IX4RqaIU?si=69Jt9KlCY9raDx8Z" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## The Ethics of Brain Augmentation

[Rising action intensifies, discussing ethical implications and societal impacts]

human rights violations

it might seem far-fetched to think human's will be made inferior to machines due to advances in artificial intelligence.
however,
cognitive enhancement might make some humans inferior to other cognitively enhanced humans. For example, take a human
with noticeably advanced mathematical skills. this human could pay, perhaps for high price initially, to have a human
chip, speciifically
designed for cognitive enhancement of mathematical studies. whilst this student does research, they would have
contextual
knowledge of important mathematical resources readily available on the chip for them to tap into.

Likewise, in a more sinister situation, a human could have a chip which enhances their cognitive ability of persuasion,
improving their ability to converse in strategic negotiations, ....

this would undeniably create inequality for the different classes of society. how can a working class person compete
with
an upper class individual who is cognitively enhanced? what would happen to a cognitively enhanced individual if after
some time, their
chip stopped working?

## The Symbiosis of Human and Machine Intelligence

[This section represents the climax, exploring the potential convergence of human and artificial intelligence]

## The Future of Human Cognition

[Falling action and resolution, summarizing the potential paths forward and their implications]

## Conclusion: An Open Question

[Final thoughts and a question for the reader to ponder]
