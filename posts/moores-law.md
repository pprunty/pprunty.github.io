---
title: "Is There a Moore's Law for the Human Brain?"
date: "2024-07-30"
description: "Exploring the interplay between technological advancements in Artificial Intelligence and the evolution of the human brain."
image: "/images/articles/brain.png"
artwork: "Surgeon examining a human brain"
---

As Artificially Intelligent (AI) systems improve at an exponential rate, are we enhancing our cognitive abilities, or
conversely, is our reliance on technology leading to a cognitive decline?

In 1965, Gordon Moore, co-founder of Intel, observed what would become known today as Moore's Law. Moore's Law states
that the number of transistors
that can be packed onto a piece of silicon doubles approximately every two years. Its limit being the size of a single
atom.
_Huh,_ it would probably be a bad idea for them to go any smaller than that right? You wouldn't want things to start
blowing up...

<figure>
  <img src="https://patrickprunty.com/images/articles/moores-law.jpg" alt="Moore's Law">
  <figcaption>Moore's Law from 1970-2020.</figcaption>
</figure>

[//]: # (The pressing question remains: Is there a Moore's Law for the human brain? As AI systems grow more sophisticated, do we risk becoming 'dumber', or does technology have the potential to enhance our cognitive functions in ways we've yet to fully understand?)

## The AI Revolution and Human Cognition

[This section serves as the hook, presenting the central question and setting up the tension between AI advancement and human cognitive capabilities]

This principle has propelled the advancement of AI, as more transistors mean more powerful hardware systems to run AI
programs on. Some fear that these AI systems might eventually surpass human capabilities and 'take over'. However,
OpenAI's latest GPT 4 model utilizes up to 1.76 trillion
parameters and still falls short of the human brain's estimated 100 trillion synaptic connections. This vast
difference highlights the unique complexity and evolutionary refinement of the human brain, which spans 3 billion years
of natural evolution.

So, is there a Moore's Law equivalent for the evolution of the human brain?

<iframe width="560" height="315" src="https://www.youtube.com/embed/aQ5PeJjZqBY?si=UIpTD8eXlovMaIoX" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## High-Performance Computing: Driving Computational Evolution

At the beating heart of AI development is high-performance computing. Companies like NVIDIA, whom specialize in
manufacturing
Graphical Processing Units (GPUs) are the modern day shuffle manufacture in today's AI gold rush. This is why NVIDIA
for a brief time held the title as the most valuable company in the world, more valuable even than than both Microsoft
and Apple. Additionally, in a recent report by The Financial Times, early Tesla and Amazon backer James Anderson backs
NVIDIA to
reach $50 trillion in market cap in the next decade, highlighting the incalculable ceiling for NVIDIA.

GPUs were initially
designed for ... however, the number of cores on GPUs lends itself to parallel computing.

Parallel computing, in simpler terms, is the ability to divide a task into smaller sub-tasks and process them
concurrently. This is similar to a team of people working together on a project, where each person handles a specific
part of the work. However, unlike human workers who may have varying efficiency, GPU cores operate uniformly, ensuring
consistent and rapid processing speeds.

While GPUs excel at parallel processing, the human brain operates differently. The brain is not naturally adept at
parallel processing; instead, it excels at integrating diverse types of information and making complex decisions based
on experience and intuition. For example, a simple test involving alternating between reading letters of the alphabet
and counting numbers demonstrates the brain's struggle with parallel tasks. Take the table below and alternate reading 
the alphabet and numbers, i.e "A, 1, B, 2, 3, C, 4, D ..."

<figure>
  <img src="https://patrickprunty.com/images/articles/table.png" alt="Moore's Law">
  <figcaption>Alphabet and Numbers Exercise</figcaption>
</figure>

Whilst this is simple when you have the ability to read the information, try without looking at the table.



## The Plasticity of the Human Brain

[Rising action begins here, discussing neuroplasticity and the brain's ability to adapt]

## Cognitive Enhancement: A New Frontier

[Rising action continues, exploring current and potential future methods of cognitive enhancement]

Elon Musk's Neuralink, for instance, aims to create a direct interface between the brain and computers, potentially
allowing for unprecedented cognitive capabilities.

evolution time for human brain to reach where it is today, first fax machine, first smartphone time, first ... use
graphic sketch

Elon Musk's neuralink & animal trials

Clip of neuralink patient on joe rogan

<iframe width="560" height="315" src="https://www.youtube.com/embed/887IX4RqaIU?si=69Jt9KlCY9raDx8Z" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## The Ethics of Brain Augmentation

[Rising action intensifies, discussing ethical implications and societal impacts]

human rights violations

it might seem far-fetched to think human's will be made inferior to machines due to advances in artificial intelligence.
however,
cognitive enhancement might make some humans inferior to other cognitively enhanced humans. For example, take a human
with noticeably advanced mathematical skills. this human could pay, perhaps for high price initially, to have a human
chip, speciifically
designed for cognitive enhancement of mathematical studies. whilst this student does research, they would have
contextual
knowledge of important mathematical resources readily available on the chip for them to tap into.

Likewise, in a more sinister situation, a human could have a chip which enhances their cognitive ability of persuasion,
improving their ability to converse in strategic negotiations, ....

this would undeniably create inequality for the different classes of society. how can a working class person compete
with
an upper class individual who is cognitively enhanced? what would happen to a cognitively enhanced individual if after
some time, their
chip stopped working?

## The Symbiosis of Human and Machine Intelligence

[This section represents the climax, exploring the potential convergence of human and artificial intelligence]

## The Future of Human Cognition

[Falling action and resolution, summarizing the potential paths forward and their implications]

## Conclusion: An Open Question

[Final thoughts and a question for the reader to ponder]
